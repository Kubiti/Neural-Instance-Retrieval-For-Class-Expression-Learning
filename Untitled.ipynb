{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1768d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "import sklearn\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "# from dataset import NRDataset\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# !ls ../python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f971b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  animals\n",
      "\n",
      "    exp : 629\n",
      "    label: 20\n",
      "    \n",
      "In  family\n",
      "\n",
      "    exp : 381\n",
      "    label: 202\n",
      "    \n",
      "In  lymphography\n",
      "\n",
      "    exp : 846\n",
      "    label: 148\n",
      "    \n",
      "In  nctrer\n",
      "\n",
      "    exp : 577\n",
      "    label: 10209\n",
      "    \n",
      "In  suramin\n",
      "\n",
      "    exp : 723\n",
      "    label: 2979\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# kb = ['mutagenesis', 'vicodi', 'semantic_bible'] #'family'\n",
    "kb = ['animals', 'family', 'lymphography', 'nctrer', 'suramin'] # 'carcinogenesis', 'vicodi'] \n",
    "for data_name in kb:\n",
    "    data_path = f'./python/training_data/train_data_{data_name}.json'\n",
    "    emb_path = f'./python/NCESData/{data_name}/embeddings/ConEx_entity_embeddings.csv'   \n",
    "    inst_emb = pd.read_csv(emb_path, index_col=0)\n",
    "    input_size = inst_emb.shape[1]\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    expr = [exp for (exp, label) in data]\n",
    "    label = [label for (exp, label) in data]\n",
    "#     print(len(label[1]))\n",
    "    print('In ', data_name)\n",
    "    print(f\"\"\"\n",
    "    exp : {len(expr)}\n",
    "    label: {len(label[1])}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f742a756-98ad-4284-bd7e-314a4fb7f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student117/Documents/aims/project/nircel/AIMS-Project/code\n",
      "In  animals\n",
      "\n",
      "    exp : 100\n",
      "    par example: ['Eagle ⊔ (HasGills ⊓ (Eel ⊔ (¬Herring)))', 'Dog ⊔ Eel ⊔ Herring', 'Snake ⊔ (Homeothermic ⊓ (Cat ⊔ (¬Platypus)))', 'Crocodile ⊔ Ostrich ⊔ T-Rex', 'Girl ⊔ Ostrich ⊔ T-Rex', 'Girl ⊔ Ostrich ⊔ Turtle', 'Penguin ⊔ Platypus ⊔ Trout', 'Herring ⊔ Shark ⊔ T-Rex', 'Crocodile ⊔ Snake ⊔ T-Rex', 'Dog ⊔ Dolphin ⊔ HasEggs']\n",
      "    \n",
      "In  family\n",
      "\n",
      "    exp : 100\n",
      "    par example: ['Brother ⊔ (Parent ⊓ (∀ hasSibling.Father))', 'Sister ⊔ (∃ hasParent.(Brother ⊓ (∃ hasParent.PersonWithASibling)))', 'Grandmother ⊓ (∃ hasChild.(¬Grandfather)) ⊓ (∀ hasChild.(¬Brother))', 'Person ⊓ (∀ hasSibling.(Grandchild ⊓ (∃ hasSibling.(¬Father))))', 'Son ⊔ (∀ married.Grandmother)', 'Grandson ⊔ (∀ hasParent.(¬Grandfather))', 'Person ⊓ (Brother ⊔ (∀ hasChild.(¬Mother))) ⊓ (∀ hasSibling.⊤)', 'PersonWithASibling ⊓ (∀ hasSibling.Mother)', 'Grandparent ⊔ (∃ married.(Male ⊓ (∀ hasParent.(¬Daughter))))', 'Brother ⊔ (Person ⊓ (Granddaughter ⊔ (∀ married.Father)))']\n",
      "    \n",
      "In  lymphography\n",
      "\n",
      "    exp : 0\n",
      "    par example: []\n",
      "    \n",
      "In  nctrer\n",
      "\n",
      "    exp : 100\n",
      "    par example: ['SingleBondEitherUpOrDownStereochemistry ⊓ (∃ second_bound_atom.(¬Atom))', 'HydrogenCount ⊔ (∃ has_bond.(¬NonStereoBond))', 'SingleOrDoubleBond ⊔ (∃ has_bond.TripleBond)', 'SingleBondUpStereochemistry ⊔ (∃ has_binding_with.(¬Atom))', 'SingleBond ⊓ (∀ second_bound_atom.(¬Atom))', 'Bond ⊔ (∃ has_bond.(¬NonStereoBond))', 'Atom ⊔ (∃ has_bond.TripleBond)', 'HydrogenCount ⊔ (∃ second_bound_atom.(¬Atom))', 'SingleOrDoubleBond ⊔ (∃ has_bond.DoubleBondDeriveCisOrTransIsomerismFromXYZCoords)', 'NonStereoBond ⊔ (∃ has_binding_with.(¬Atom))']\n",
      "    \n",
      "In  suramin\n",
      "\n",
      "    exp : 100\n",
      "    par example: ['Hydrogen-8 ⊔ (∃ inBond.Sulfur-78)', 'Bromine ⊔ (∃ inBond.(Hydrogen-8 ⊔ Oxygen-51))', 'Bromine ⊔ (∃ inBond.(Hydrogen-1 ⊔ Oxygen-40))', 'Bromine ⊔ (∃ inBond.(Carbon-14 ⊔ Carbon-27))', 'Carbon-14 ⊔ Hydrogen ⊔ Oxygen-40', 'Bromine ⊔ (∃ inBond.(Hydrogen-8 ⊔ Nitrogen))', 'Bond-1 ⊓ (∀ inBond.(¬Nitrogen-32))', 'Carbon-14 ⊔ Nitrogen ⊔ Oxygen-45', 'Bond ⊓ (∀ inBond.(¬Carbon-14))', 'Bromine ⊔ (∃ inBond.(Carbon ⊔ Nitrogen-32))']\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "kb = ['animals', 'family', 'lymphography', 'nctrer', 'suramin'] # 'carcinogenesis', 'vicodi'] \n",
    "for data_name in kb:\n",
    "    data_path = f'./python/testing_data/{data_name}/Data.json'\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    expr = [exp for (exp, label) in data]\n",
    "    # label = [label for (exp, label) in data]\n",
    "#     print(len(label[1]))\n",
    "    print('In ', data_name)\n",
    "    print(f\"\"\"\n",
    "    exp : {len(expr)}\n",
    "    par example: {expr[:10]}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c072935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55cf3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exprs = [exp for (exp, label) in data]\n",
    "# len(exprs)\n",
    "# exprs[:5]\n",
    "# data[0]\n",
    "# expression\n",
    "def neg_check(exp):\n",
    "    return (' ' not in exp) and ('¬' in exp)\n",
    "\n",
    "def three_check(exp):\n",
    "    return quant(exp) or const(exp)\n",
    "\n",
    "def inter_check(expr):\n",
    "    return expr.count(' ') == 2 and ('⊓' in expr)\n",
    "\n",
    "def union_check(expr):\n",
    "    return expr.count(' ') == 2 and ('⊔' in expr)\n",
    "\n",
    "def exist_check(expr):\n",
    "    return expr.count(' ') == 2 and ('∃' in expr)\n",
    "\n",
    "def forall_check(expr):\n",
    "    return expr.count(' ') == 2 and ('∀' in expr)\n",
    "\n",
    "def top_bot(exp):\n",
    "    return (('⊤' not in exp) and ('⊥' not in exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee449ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         In animals:\n",
      "         atomic: 24 + 24 = 48\t \n",
      "\n",
      "\n",
      "         Three: 304\n",
      "         Disjunction: ['T-Rex ⊔ Turtle', 'Eel ⊔ Trout'] ['HasEggs ⊔ (¬HasMilk)', 'Dog ⊔ (¬Homeothermic)']\n",
      "            Pos: 240 + Neg 33 = 273\n",
      "            \n",
      "        Conjunction: ['HasEggs ⊓ Homeothermic'] ['HasEggs ⊓ (¬HasMilk)', 'HasMilk ⊓ (¬Cat)']\n",
      "            Pos: 1 + Neg 30 = 31\n",
      "            \n",
      "        Universal: [] []\n",
      "            Pos: 0 + Neg 0 = 0\n",
      "            \n",
      "        Existential: [] []\n",
      "            Pos: 0 + Neg 0 = 0\n",
      "\n",
      "         \n",
      "         other: 352\n",
      "         Total: 704\n",
      "     \n",
      "\n",
      "         In family:\n",
      "         atomic: 15 + 15 = 32\t \n",
      "\n",
      "\n",
      "         Three: 357\n",
      "         Disjunction: ['Child ⊔ Male', 'Grandchild ⊔ Grandfather'] ['Grandchild ⊔ (¬Grandfather)', 'Grandchild ⊔ (¬Grandparent)']\n",
      "            Pos: 73 + Neg 70 = 143\n",
      "            \n",
      "        Conjunction: ['Grandchild ⊓ Grandfather', 'Grandchild ⊓ Grandparent'] ['Grandchild ⊓ (¬Grandfather)', 'Male ⊓ (¬Grandchild)']\n",
      "            Pos: 21 + Neg 88 = 109\n",
      "            \n",
      "        Universal: ['∀ hasChild.Daughter', '∀ married.Daughter'] ['∀ hasSibling.(¬Grandfather)', '∀ hasChild.(¬Grandson)']\n",
      "            Pos: 26 + Neg 26 = 52\n",
      "            \n",
      "        Existential: ['∃ hasChild.Daughter', '∃ married.Daughter'] ['∃ hasSibling.(¬Grandfather)', '∃ hasChild.(¬Grandson)']\n",
      "            Pos: 30 + Neg 23 = 53\n",
      "\n",
      "         \n",
      "         other: 23862\n",
      "         Total: 24251\n",
      "     \n",
      "\n",
      "         In lymphography:\n",
      "         atomic: 46 + 46 = 92\t \n",
      "\n",
      "\n",
      "         Three: 4076\n",
      "         Disjunction: ['Bl_of_lymph_s5 ⊔ CIN14_Lac_Central', 'CIN14_Lac_Margin ⊔ DIN13_Lacunar'] ['CIN14_Lac_Central ⊔ (¬Bl_of_lymph_s5)', 'DislocationOf17 ⊔ (¬SF16_Chalices)']\n",
      "            Pos: 942 + Neg 1285 = 2227\n",
      "            \n",
      "        Conjunction: ['Bl_of_lymph_s5 ⊓ CIN14_Lac_Central', 'CIN14_Lac_Margin ⊓ DIN13_Lacunar'] ['CIN14_Lac_Central ⊓ (¬Bl_of_lymph_s5)', 'DislocationOf17 ⊓ (¬SF16_Chalices)']\n",
      "            Pos: 626 + Neg 1223 = 1849\n",
      "            \n",
      "        Universal: [] []\n",
      "            Pos: 0 + Neg 0 = 0\n",
      "            \n",
      "        Existential: [] []\n",
      "            Pos: 0 + Neg 0 = 0\n",
      "\n",
      "         \n",
      "         other: 0\n",
      "         Total: 4168\n",
      "     \n",
      "\n",
      "         In nctrer:\n",
      "         atomic: 13 + 13 = 26\t \n",
      "\n",
      "\n",
      "         Three: 79\n",
      "         Disjunction: ['AtomSymbol ⊔ Molecule', 'DoubleOrAromaticBond ⊔ NonStereoBond'] ['SingleBondUpStereochemistry ⊔ (¬SingleBond)', 'SingleBondUpStereochemistry ⊔ (¬SingleOrDoubleBond)']\n",
      "            Pos: 54 + Neg 7 = 61\n",
      "            \n",
      "        Conjunction: [] ['SingleOrDoubleBond ⊓ (¬SingleBondDownStereochemistry)', 'Bond ⊓ (¬SingleBondEitherUpOrDownStereochemistry)']\n",
      "            Pos: 0 + Neg 5 = 5\n",
      "            \n",
      "        Universal: ['∀ has_binding_with.TripleBond', '∀ has_bond.NonStereoBond'] ['∀ has_binding_with.(¬Atom)', '∀ has_bond.(¬SingleBondDownStereochemistry)']\n",
      "            Pos: 2 + Neg 4 = 6\n",
      "            \n",
      "        Existential: ['∃ has_bond.DoubleBondDeriveCisOrTransIsomerismFromXYZCoords', '∃ has_bond.TripleBond'] ['∃ has_bond.(¬NonStereoBond)', '∃ has_binding_with.(¬Atom)']\n",
      "            Pos: 3 + Neg 4 = 7\n",
      "\n",
      "         \n",
      "         other: 143\n",
      "         Total: 248\n",
      "     \n",
      "\n",
      "         In suramin:\n",
      "         atomic: 22 + 22 = 44\t \n",
      "\n",
      "\n",
      "         Three: 267\n",
      "         Disjunction: ['Nitrogen-32 ⊔ Oxygen-40', 'Hydrogen-3 ⊔ Oxygen-40'] ['Oxygen-49 ⊔ (¬Oxygen)', 'Carbon-14 ⊔ (¬Atom)']\n",
      "            Pos: 197 + Neg 26 = 223\n",
      "            \n",
      "        Conjunction: [] ['Atom ⊓ (¬Oxygen-40)', 'Atom ⊓ (¬Oxygen-51)']\n",
      "            Pos: 0 + Neg 21 = 21\n",
      "            \n",
      "        Universal: ['∀ inBond.Carbon', '∀ inBond.Carbon-22'] ['∀ inBond.(¬Carbon-14)', '∀ inBond.(¬Carbon-10)']\n",
      "            Pos: 3 + Neg 17 = 20\n",
      "            \n",
      "        Existential: ['∃ inBond.Hydrogen-1', '∃ inBond.Sulfur-78'] ['∃ inBond.(¬Carbon-22)']\n",
      "            Pos: 2 + Neg 1 = 3\n",
      "\n",
      "         \n",
      "         other: 403\n",
      "         Total: 714\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "kb = ['animals', 'family', 'lymphography',  'nctrer', 'suramin', ] \n",
    "dataset = []\n",
    "for data_name in kb:\n",
    "    # data_path = f'./python/training_data/train_data_{data_name}.json'\n",
    "    data_path = f'./python/training_data/prev/train_data_{data_name}.json'\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    const = lambda expr: (expr.count(' ') == 2 and not ('∃' in expr or '∀' in expr))\n",
    "    quant = lambda expr:  (not ('⊔' in expr or '⊓' in expr)) and ('∃' in expr or '∀' in expr)\n",
    "#     expression = [expr for expr in exprs if quant(expr) or const(expr)]\n",
    "#     expression = [expr for expr in exprs]\n",
    "    exprs = [exp for (exp, label) in data]\n",
    "\n",
    "    # expression\n",
    "    # split = [expr.]\n",
    "    atomic = [[],[]]\n",
    "    three = {'conj': [[], []], 'disj': [[], []], 'exist': [[], []], 'uni': [[], []]}\n",
    "    other = []\n",
    "    for ele in exprs:\n",
    "    #     parts = []\n",
    "        if ' ' not in ele:\n",
    "#             atomic.append(ele)\n",
    "    #         print(ele)\n",
    "            if '¬' in ele:\n",
    "                atomic[0].append(ele)\n",
    "            else:\n",
    "                atomic[1].append(ele)\n",
    "\n",
    "        # elif inter_check(ele):\n",
    "        #     print(ele)\n",
    "    # return expr.count(' ') == 2 and ('⊓' in expr)\n",
    "\n",
    "        elif (quant(ele) or const(ele)):\n",
    "            # three.append(ele)\n",
    "            if(' ⊔ ' in ele):\n",
    "    #             print(ele)\n",
    "                parts = ele.split(' ⊔ ')\n",
    "                parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "                if '¬' in ele:\n",
    "                    three['disj'][1].append(ele)\n",
    "                else:\n",
    "                    three['disj'][0].append(ele)\n",
    "                \n",
    "            elif (' ⊓ ' in ele):\n",
    "    #             print(ele)\n",
    "                parts = ele.split(' ⊓ ')\n",
    "                parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "                if '¬' in ele:\n",
    "                    three['conj'][1].append(ele)\n",
    "                else:\n",
    "                    three['conj'][0].append(ele)\n",
    "                \n",
    "            else:\n",
    "    #             print(ele)\n",
    "                if (ele.startswith('∀')):\n",
    "                    parts = ele.split(' ')[1].split('.')\n",
    "                    parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "                    if '¬' in ele:\n",
    "                        three['uni'][1].append(ele)\n",
    "                    else:\n",
    "                        three['uni'][0].append(ele)\n",
    "                if (ele.startswith('∃')):\n",
    "                    parts = ele.split(' ')[1].split('.')\n",
    "                    parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "                    if '¬' in ele:\n",
    "                        three['exist'][1].append(ele)\n",
    "                    else:\n",
    "                        three['exist'][0].append(ele)\n",
    "\n",
    "        else:\n",
    "#             print(ele)\n",
    "            other.append(ele)\n",
    "        disj = len(three['disj'][1] + three['disj'][0])\n",
    "        conj = len(three['conj'][1] + three['conj'][0])\n",
    "        uni = len(three['uni'][1] + three['uni'][0])\n",
    "        exist = len(three['exist'][1] + three['exist'][0])\n",
    "        atomic_len = len(atomic[0]) + len(atomic[1])\n",
    "        other_len = len(other)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "         In {data_name}:\n",
    "         atomic: {len(atomic[0])} + {len(atomic[0])} = {len(atomic[0]) + len(atomic[1])}\\t \n",
    "\n",
    "\n",
    "         Three: {disj + conj + uni + exist}\n",
    "         Disjunction: {three['disj'][0][:2]} {three['disj'][1][:2]}\n",
    "            Pos: {len(three['disj'][0])} + Neg {len(three['disj'][1])} = {disj}\n",
    "            \n",
    "        Conjunction: {three['conj'][0][:2]} {three['conj'][1][:2]}\n",
    "            Pos: {len(three['conj'][0])} + Neg {len(three['conj'][1])} = {conj}\n",
    "            \n",
    "        Universal: {three['uni'][0][:2]} {three['uni'][1][:2]}\n",
    "            Pos: {len(three['uni'][0])} + Neg {len(three['uni'][1])} = {uni}\n",
    "            \n",
    "        Existential: {three['exist'][0][:2]} {three['exist'][1][:2]}\n",
    "            Pos: {len(three['exist'][0])} + Neg {len(three['exist'][1])} = {exist}\n",
    "\n",
    "         \n",
    "         other: {len(other)}\n",
    "         Total: {atomic_len + disj + conj + uni + exist + other_len}\n",
    "     \"\"\")\n",
    "    # dataset.append([data_name, ['atomic'\n",
    "    # with open(f\"./dataset_info/{data_name}/{data_name}_accuracies_{model_name}.json\", \"w\") as file:\n",
    "    #         json.dump([('train accuracy', avg_train_accarr), ('validation_accuracy', avg_validation_accarr)] , file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f90079eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dijfe  dfjie'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comp(quant(ele) or const(ele)):\n",
    "        three.append(ele)\n",
    "        if(' ⊔ ' in ele):\n",
    "            parts = ele.split(' ⊔ ')\n",
    "            parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "        elif (' ⊓ ' in ele):\n",
    "            parts = ele.split(' ⊓ ')\n",
    "            parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "        else:\n",
    "            if (ele.startswith('∀')):\n",
    "                parts = ele.split(' ')[1].split('.')\n",
    "                parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n",
    "            if (ele.startswith('∃')):\n",
    "                parts = ele.split(' ')[1].split('.')\n",
    "                parts = [part.strip().replace('(', '').replace(')', '') for part in parts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29f945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ele in other:\n",
    "#     level = ele.count('(')\n",
    "#     if ele.startswith('('):\n",
    "#         print(ele, 'level: ', level)\n",
    "        \n",
    "# # [ele for ele in other if ele.startswith('(')]\n",
    "# print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206fa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = '(Female ⊔ Son) ⊓ (¬Grandchild)'\n",
    "keys = {'Female': 3, 'Son': 2, 'Grandchild': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56478f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_all_bracket_contents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m expression \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(Person ⊓ (Male ⊔ (∃ hasChild.(¬Grandparent)))) ⊔ (∃ hasParent.Female)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 21\u001b[0m bracket_contents \u001b[38;5;241m=\u001b[39m \u001b[43mextract_all_bracket_contents\u001b[49m(expression)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(bracket_contents)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_all_bracket_contents' is not defined"
     ]
    }
   ],
   "source": [
    "# '(Person ⊓ (Male ⊔ (∃ hasChild.(¬Grandparent)))) ⊔ (∃ hasParent.Female)'.count(')')\n",
    "\n",
    "def evaluate_parentheses(expression):\n",
    "    while '(' in expression:\n",
    "        open_idx = None\n",
    "        close_idx = None\n",
    "\n",
    "        for idx, item in enumerate(expression):\n",
    "            if item == '(':\n",
    "                open_idx = idx\n",
    "            if item == ')':\n",
    "                close_idx = idx\n",
    "        inner_results = evaluate_exp(expression[open_idx + 1: close_idx])  \n",
    "        \n",
    "        exercise[open_idx: close_idx + 1] = [inner_result]\n",
    "\n",
    "    return exercise\n",
    "\n",
    "# Example usage:\n",
    "expression = '(Person ⊓ (Male ⊔ (∃ hasChild.(¬Grandparent)))) ⊔ (∃ hasParent.Female)'\n",
    "bracket_contents = evaluate_parentheses(expression)\n",
    "\n",
    "print(bracket_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_exp(exp):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbef3420-acec-430d-9dcf-f62cd9ff0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left [[0.         0.46768046]\n",
      " [0.79302339 1.13870025]\n",
      " [1.60638071 2.31806837]\n",
      " [2.54174163 3.13142569]\n",
      " [3.80244548 4.04645267]\n",
      " [4.59546887 5.42916012]]\n",
      "left[:,0] [0.         0.79302339 1.60638071 2.54174163 3.80244548 4.59546887]\n",
      "left.flatten() [0.         0.46768046 0.79302339 1.13870025 1.60638071 2.31806837\n",
      " 2.54174163 3.13142569 3.80244548 4.04645267 4.59546887 5.42916012]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "# Creating dataset\n",
    "size = 6\n",
    "cars = ['AUDI', 'BMW', 'FORD',\n",
    "        'TESLA', 'JAGUAR', 'MERCEDES']\n",
    " \n",
    "data = np.array([[23, 16], [17, 23],\n",
    "                 [35, 11], [29, 33],\n",
    "                 [12, 27], [41, 42]])\n",
    " \n",
    "# normalizing data to 2 pi\n",
    "norm = data / np.sum(data)*2 * np.pi\n",
    " \n",
    "# obtaining ordinates of bar edges\n",
    "left = np.cumsum(np.append(0,\n",
    "                           norm.flatten()[:-1])).reshape(data.shape)\n",
    "print('left', left)\n",
    "print('left[:,0]', left[:,0])\n",
    "print('left.flatten()', left.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4eeef-27ab-40d5-8bd4-f96844daf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating color scale\n",
    "cmap = plt.get_cmap(\"tab20c\")\n",
    "outer_colors = cmap(np.arange(6)*4)\n",
    "inner_colors = cmap(np.array([1, 2, 5, 6, 9,\n",
    "                              10, 12, 13, 15,\n",
    "                              17, 18, 20]))\n",
    " \n",
    "# Creating plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7),\n",
    "                       subplot_kw=dict(polar=True))\n",
    " \n",
    "ax.bar(x=left[:, 0],\n",
    "       width=norm.sum(axis=1),\n",
    "       bottom=1-size,\n",
    "       height=size,\n",
    "       color=outer_colors,\n",
    "       edgecolor='w',\n",
    "       linewidth=1,\n",
    "       align=\"edge\")\n",
    " \n",
    "ax.bar(x=left.flatten(),\n",
    "       width=norm.flatten(),\n",
    "       bottom=1-2 * size,\n",
    "       height=size,\n",
    "       color=inner_colors,\n",
    "       edgecolor='w',\n",
    "       linewidth=1,\n",
    "       align=\"edge\")\n",
    " \n",
    "ax.set(title=\"Nested pie chart\")\n",
    "ax.set_axis_off()\n",
    " \n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "802ec598-8ef5-4128-8332-b8d749c6b7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grandmother ⊔ 1', '3']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'Grandmother ⊔ 1 ⊓ 3'.split(' ⊓ ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4567dc1d-f9fc-4a08-bf75-3a73fcd8103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grandmother', '1 ⊓ 3']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Grandmother ⊓ 1 ⊓ 3'.split(' ⊓ ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bd137fc-9bf3-437e-bea2-580ff858be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grandmother ⊓ 1\n"
     ]
    }
   ],
   "source": [
    "input_string = \"Grandmother ⊓ 1 ⊓ 3\"\n",
    "\n",
    "# Split the string and take the first two parts\n",
    "parts = input_string.split(\" ⊓ \")\n",
    "result = \" ⊓ \".join(parts[:2])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1671834-00b3-4887-a5a6-8da822ac88f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_plot.png  dataset.py\t\t\t   metrics\t train_comp.py\n",
      "check.ipynb\t   dice-embeddings.code-workspace  model.py\t traindata.py\n",
      "concept_length.py  error\t\t\t   plot.ipynb\t trained_models\n",
      "dataset.eps\t   expr_learner.py\t\t   plot.py\t training_data\n",
      "dataset_info\t   helper.py\t\t\t   __pycache__\t training.py\n",
      "dataset.pdf\t   inference_on_test.ipynb\t   test_comp.py  train.py\n",
      "dataset.png\t   main.py\t\t\t   testing_data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './metrics/animals/animals_testing_f1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls python\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concept_length\n",
      "File \u001b[0;32m~/Documents/aims/project/nircel/AIMS-Project/code/python/concept_length.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m exp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./testing_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Data.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metrics/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_performance_per_len.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     33\u001b[0m     f1_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# f1_scores = []\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# print(f1_data)\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './metrics/animals/animals_testing_f1.json'"
     ]
    }
   ],
   "source": [
    "!ls python \n",
    "from python import concept_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a6a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(concept_name: str) -> list:\n",
    "        list_ordered_pieces = []\n",
    "        i = 0\n",
    "        while i < len(concept_name):\n",
    "            concept = ''\n",
    "            while i < len(concept_name) and not concept_name[i] in ['(', ')', '⊔', '⊓', '∃', '∀', '¬', '.', ' ']:\n",
    "                concept += concept_name[i]\n",
    "                i += 1\n",
    "            if concept:\n",
    "                list_ordered_pieces.append(concept)\n",
    "            i += 1\n",
    "        return list_ordered_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bfe753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concept_length(concept_string):\n",
    "    spec_chars = [\"∃\", \"∀\", \"¬\", \"⊔\", \"⊓\"]\n",
    "    return len(decompose(concept_string)) + sum(map(concept_string.count, spec_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d909caa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(data[:5])\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m expressions \u001b[38;5;241m=\u001b[39m [(expr, label) \u001b[38;5;28;01mfor\u001b[39;00m (expr, label) \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(expressions[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(data[:5])\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m expressions \u001b[38;5;241m=\u001b[39m [(expr, label) \u001b[38;5;28;01mfor\u001b[39;00m (expr, label) \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(expressions[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "kb = ['lymphography']\n",
    "for data_name in kb:\n",
    "    exp_path = f'./NCESData/{data_name}/training_data/Data.json'\n",
    "\n",
    "    with open(exp_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # print(data[:5])\n",
    "    expressions = [(expr, label) for (expr, label) in data]\n",
    "\n",
    "    print(expressions[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4174efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
